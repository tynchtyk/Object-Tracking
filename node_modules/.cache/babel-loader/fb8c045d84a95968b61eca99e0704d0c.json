{"ast":null,"code":"import _regeneratorRuntime from \"/home/tchbek/Desktop/object-detection-react/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/home/tchbek/Desktop/object-detection-react/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport { useEffect } from 'react';\n\nvar renderPredictions = function renderPredictions(predictions, canvasRef) {\n  var ctx = canvasRef.current.getContext('2d'); // Font options.\n\n  var font = '16px sans-serif';\n  ctx.font = font;\n  ctx.textBaseline = 'top';\n  predictions.forEach(function (prediction) {\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n    var x = prediction.bbox[0];\n    var y = prediction.bbox[1];\n    var width = prediction.bbox[2];\n    var height = prediction.bbox[3]; // Draw the bounding box.\n    //ctx.strokeStyle = '#00FFFF'\n    //ctx.lineWidth = 4\n    //ctx.strokeRect(x, y, width, height*2)\n    //fill circle wihth color\n\n    ctx.beginPath();\n    ctx.arc(x + width / 2, y + height, (width + height) / 2.7, 0, 2 * Math.PI, false);\n    ctx.filter = \"blur(8px)\";\n    ctx.fillStyle = 'gray';\n    ctx.fill(); // Draw the label background.\n\n    /*ctx.fillStyle = '#00FFFF'\n    const textWidth = ctx.measureText(prediction.class).width\n    const textHeight = parseInt(font, 10) // base 10\n    ctx.fillRect(x, y, textWidth + 4, textHeight + 4)\n    */\n  });\n};\n\nvar detectFrame =\n/*#__PURE__*/\nfunction () {\n  var _ref = _asyncToGenerator(\n  /*#__PURE__*/\n  _regeneratorRuntime.mark(function _callee(model, videoRef, canvasRef) {\n    var predictions;\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            _context.next = 2;\n            return model.detect(videoRef.current);\n\n          case 2:\n            predictions = _context.sent;\n            renderPredictions(predictions, canvasRef);\n            requestAnimationFrame(function () {\n              detectFrame(model, videoRef, canvasRef);\n            });\n\n          case 5:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n\n  return function detectFrame(_x, _x2, _x3) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nvar useBoxRenderer = function useBoxRenderer(model, videoRef, canvasRef, shouldRender) {\n  useEffect(function () {\n    if (model && shouldRender) {\n      detectFrame(model, videoRef, canvasRef);\n    }\n  }, [canvasRef, model, shouldRender, videoRef]);\n};\n\nexport default useBoxRenderer;","map":{"version":3,"sources":["/home/tchbek/Desktop/object-detection-react/src/useBoxRenderer.js"],"names":["useEffect","renderPredictions","predictions","canvasRef","ctx","current","getContext","font","textBaseline","forEach","prediction","clearRect","canvas","width","height","x","bbox","y","beginPath","arc","Math","PI","filter","fillStyle","fill","detectFrame","model","videoRef","detect","requestAnimationFrame","useBoxRenderer","shouldRender"],"mappings":";;AAAA,SAASA,SAAT,QAA0B,OAA1B;;AAEA,IAAMC,iBAAiB,GAAG,SAApBA,iBAAoB,CAACC,WAAD,EAAcC,SAAd,EAA4B;AACpD,MAAMC,GAAG,GAAGD,SAAS,CAACE,OAAV,CAAkBC,UAAlB,CAA6B,IAA7B,CAAZ,CADoD,CAEpD;;AACA,MAAMC,IAAI,GAAG,iBAAb;AACAH,EAAAA,GAAG,CAACG,IAAJ,GAAWA,IAAX;AACAH,EAAAA,GAAG,CAACI,YAAJ,GAAmB,KAAnB;AACAN,EAAAA,WAAW,CAACO,OAAZ,CAAoB,UAAAC,UAAU,EAAI;AAChCN,IAAAA,GAAG,CAACO,SAAJ,CAAc,CAAd,EAAiB,CAAjB,EAAoBP,GAAG,CAACQ,MAAJ,CAAWC,KAA/B,EAAsCT,GAAG,CAACQ,MAAJ,CAAWE,MAAjD;AACA,QAAMC,CAAC,GAAGL,UAAU,CAACM,IAAX,CAAgB,CAAhB,CAAV;AACA,QAAMC,CAAC,GAAGP,UAAU,CAACM,IAAX,CAAgB,CAAhB,CAAV;AACA,QAAMH,KAAK,GAAGH,UAAU,CAACM,IAAX,CAAgB,CAAhB,CAAd;AACA,QAAMF,MAAM,GAAGJ,UAAU,CAACM,IAAX,CAAgB,CAAhB,CAAf,CALgC,CAMhC;AAEA;AACA;AACA;AAEA;;AACAZ,IAAAA,GAAG,CAACc,SAAJ;AACAd,IAAAA,GAAG,CAACe,GAAJ,CAAQJ,CAAC,GAACF,KAAK,GAAC,CAAhB,EAAmBI,CAAC,GAACH,MAArB,EAA6B,CAACD,KAAK,GAACC,MAAP,IAAe,GAA5C,EAAiD,CAAjD,EAAoD,IAAIM,IAAI,CAACC,EAA7D,EAAiE,KAAjE;AACAjB,IAAAA,GAAG,CAACkB,MAAJ,GAAa,WAAb;AACAlB,IAAAA,GAAG,CAACmB,SAAJ,GAAgB,MAAhB;AACAnB,IAAAA,GAAG,CAACoB,IAAJ,GAjBgC,CAqBhC;;AACA;;;;;AAKD,GA3BD;AA8BD,CApCD;;AAsCA,IAAMC,WAAW;AAAA;AAAA;AAAA;AAAA;AAAA,2BAAG,iBAAOC,KAAP,EAAcC,QAAd,EAAwBxB,SAAxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBACQuB,KAAK,CAACE,MAAN,CAAaD,QAAQ,CAACtB,OAAtB,CADR;;AAAA;AACZH,YAAAA,WADY;AAElBD,YAAAA,iBAAiB,CAACC,WAAD,EAAcC,SAAd,CAAjB;AACA0B,YAAAA,qBAAqB,CAAC,YAAM;AAC1BJ,cAAAA,WAAW,CAACC,KAAD,EAAQC,QAAR,EAAkBxB,SAAlB,CAAX;AACD,aAFoB,CAArB;;AAHkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAXsB,WAAW;AAAA;AAAA;AAAA,GAAjB;;AAQA,IAAMK,cAAc,GAAG,SAAjBA,cAAiB,CAACJ,KAAD,EAAQC,QAAR,EAAkBxB,SAAlB,EAA6B4B,YAA7B,EAA8C;AACnE/B,EAAAA,SAAS,CAAC,YAAM;AACd,QAAI0B,KAAK,IAAIK,YAAb,EAA2B;AACzBN,MAAAA,WAAW,CAACC,KAAD,EAAQC,QAAR,EAAkBxB,SAAlB,CAAX;AACD;AACF,GAJQ,EAIN,CAACA,SAAD,EAAYuB,KAAZ,EAAmBK,YAAnB,EAAiCJ,QAAjC,CAJM,CAAT;AAKD,CAND;;AAQA,eAAeG,cAAf","sourcesContent":["import { useEffect } from 'react'\n\nconst renderPredictions = (predictions, canvasRef) => {\n  const ctx = canvasRef.current.getContext('2d')\n  // Font options.\n  const font = '16px sans-serif'\n  ctx.font = font\n  ctx.textBaseline = 'top'\n  predictions.forEach(prediction => {\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height)\n    const x = prediction.bbox[0]\n    const y = prediction.bbox[1]\n    const width = prediction.bbox[2]\n    const height = prediction.bbox[3]\n    // Draw the bounding box.\n    \n    //ctx.strokeStyle = '#00FFFF'\n    //ctx.lineWidth = 4\n    //ctx.strokeRect(x, y, width, height*2)\n    \n    //fill circle wihth color\n    ctx.beginPath();\n    ctx.arc(x+width/2, y+height, (width+height)/2.7, 0, 2 * Math.PI, false);\n    ctx.filter = \"blur(8px)\"\n    ctx.fillStyle = 'gray';\n    ctx.fill();\n    \n\n  \n    // Draw the label background.\n    /*ctx.fillStyle = '#00FFFF'\n    const textWidth = ctx.measureText(prediction.class).width\n    const textHeight = parseInt(font, 10) // base 10\n    ctx.fillRect(x, y, textWidth + 4, textHeight + 4)\n    */\n  })\n  \n  \n}\n\nconst detectFrame = async (model, videoRef, canvasRef) => {\n  const predictions = await model.detect(videoRef.current)\n  renderPredictions(predictions, canvasRef)\n  requestAnimationFrame(() => {\n    detectFrame(model, videoRef, canvasRef)\n  })\n}\n\nconst useBoxRenderer = (model, videoRef, canvasRef, shouldRender) => {\n  useEffect(() => {\n    if (model && shouldRender) {\n      detectFrame(model, videoRef, canvasRef)\n    }\n  }, [canvasRef, model, shouldRender, videoRef])\n}\n\nexport default useBoxRenderer\n"]},"metadata":{},"sourceType":"module"}