{"ast":null,"code":"import _regeneratorRuntime from \"/home/tchbek/Desktop/object-detection-react/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/home/tchbek/Desktop/object-detection-react/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport { useEffect } from 'react';\n\nvar renderPredictions = function renderPredictions(predictions, canvasRef) {\n  var ctx = canvasRef.current.getContext('2d');\n  ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height); // Font options.\n\n  var font = '16px sans-serif';\n  ctx.font = font;\n  ctx.textBaseline = 'top';\n  predictions.forEach(function (prediction) {\n    var x = prediction.bbox[0];\n    var y = prediction.bbox[1];\n    var width = prediction.bbox[2];\n    var height = prediction.bbox[3]; // Draw the bounding box.\n\n    ctx.strokeStyle = '#00FFFF';\n    ctx.lineWidth = 4;\n    ctx.strokeRect(x, y, width, height * 2);\n    var pixelData = ctx.getImageData(x, y, width, height * 2);\n    var avg, i; // apply a  simple greyscale transformation\n\n    for (i = 0; i < pixelData.data.length; i++) {\n      pixelData.data[i] = '#000FFF';\n      pixelData.data[i + 1] = '#000FFF';\n      pixelData.data[i + 2] = '#000FFF';\n    }\n\n    ctx.putImageData(pixelData, 0, 0); // Draw the label background.\n\n    /*ctx.fillStyle = '#00FFFF'\n    const textWidth = ctx.measureText(prediction.class).width\n    const textHeight = parseInt(font, 10) // base 10\n    ctx.fillRect(x, y, textWidth + 4, textHeight + 4)\n    */\n  });\n  /*\n  predictions.forEach(prediction => {\n    const x = prediction.bbox[0]\n    const y = prediction.bbox[1]\n    // Draw the text last to ensure it's on top.\n    ctx.fillStyle = '#000000'\n    ctx.fillText(prediction.class, x, y)\n  })\n  */\n};\n\nvar detectFrame =\n/*#__PURE__*/\nfunction () {\n  var _ref = _asyncToGenerator(\n  /*#__PURE__*/\n  _regeneratorRuntime.mark(function _callee(model, videoRef, canvasRef) {\n    var predictions;\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            _context.next = 2;\n            return model.detect(videoRef.current);\n\n          case 2:\n            predictions = _context.sent;\n            renderPredictions(predictions, canvasRef);\n            requestAnimationFrame(function () {\n              detectFrame(model, videoRef, canvasRef);\n            });\n\n          case 5:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n\n  return function detectFrame(_x, _x2, _x3) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nvar useBoxRenderer = function useBoxRenderer(model, videoRef, canvasRef, shouldRender) {\n  useEffect(function () {\n    if (model && shouldRender) {\n      detectFrame(model, videoRef, canvasRef);\n    }\n  }, [canvasRef, model, shouldRender, videoRef]);\n};\n\nexport default useBoxRenderer;","map":{"version":3,"sources":["/home/tchbek/Desktop/object-detection-react/src/useBoxRenderer.js"],"names":["useEffect","renderPredictions","predictions","canvasRef","ctx","current","getContext","clearRect","canvas","width","height","font","textBaseline","forEach","prediction","x","bbox","y","strokeStyle","lineWidth","strokeRect","pixelData","getImageData","avg","i","data","length","putImageData","detectFrame","model","videoRef","detect","requestAnimationFrame","useBoxRenderer","shouldRender"],"mappings":";;AAAA,SAASA,SAAT,QAA0B,OAA1B;;AAEA,IAAMC,iBAAiB,GAAG,SAApBA,iBAAoB,CAACC,WAAD,EAAcC,SAAd,EAA4B;AACpD,MAAMC,GAAG,GAAGD,SAAS,CAACE,OAAV,CAAkBC,UAAlB,CAA6B,IAA7B,CAAZ;AACAF,EAAAA,GAAG,CAACG,SAAJ,CAAc,CAAd,EAAiB,CAAjB,EAAoBH,GAAG,CAACI,MAAJ,CAAWC,KAA/B,EAAsCL,GAAG,CAACI,MAAJ,CAAWE,MAAjD,EAFoD,CAGpD;;AACA,MAAMC,IAAI,GAAG,iBAAb;AACAP,EAAAA,GAAG,CAACO,IAAJ,GAAWA,IAAX;AACAP,EAAAA,GAAG,CAACQ,YAAJ,GAAmB,KAAnB;AACAV,EAAAA,WAAW,CAACW,OAAZ,CAAoB,UAAAC,UAAU,EAAI;AAChC,QAAMC,CAAC,GAAGD,UAAU,CAACE,IAAX,CAAgB,CAAhB,CAAV;AACA,QAAMC,CAAC,GAAGH,UAAU,CAACE,IAAX,CAAgB,CAAhB,CAAV;AACA,QAAMP,KAAK,GAAGK,UAAU,CAACE,IAAX,CAAgB,CAAhB,CAAd;AACA,QAAMN,MAAM,GAAGI,UAAU,CAACE,IAAX,CAAgB,CAAhB,CAAf,CAJgC,CAKhC;;AACAZ,IAAAA,GAAG,CAACc,WAAJ,GAAkB,SAAlB;AACAd,IAAAA,GAAG,CAACe,SAAJ,GAAgB,CAAhB;AACAf,IAAAA,GAAG,CAACgB,UAAJ,CAAeL,CAAf,EAAkBE,CAAlB,EAAqBR,KAArB,EAA4BC,MAAM,GAAC,CAAnC;AAEA,QAAIW,SAAS,GAAGjB,GAAG,CAACkB,YAAJ,CAAiBP,CAAjB,EAAoBE,CAApB,EAAwBR,KAAxB,EAA+BC,MAAM,GAAC,CAAtC,CAAhB;AACA,QAAIa,GAAJ,EAASC,CAAT,CAXgC,CAYhC;;AACA,SAAKA,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAGH,SAAS,CAACI,IAAV,CAAeC,MAA/B,EAAuCF,CAAC,EAAxC,EAA8C;AAC5CH,MAAAA,SAAS,CAACI,IAAV,CAAgBD,CAAhB,IAAsB,SAAtB;AACAH,MAAAA,SAAS,CAACI,IAAV,CAAgBD,CAAC,GAAG,CAApB,IAA0B,SAA1B;AACAH,MAAAA,SAAS,CAACI,IAAV,CAAgBD,CAAC,GAAG,CAApB,IAA0B,SAA1B;AACD;;AAEDpB,IAAAA,GAAG,CAACuB,YAAJ,CAAiBN,SAAjB,EAA4B,CAA5B,EAA+B,CAA/B,EAnBgC,CAuBhC;;AACA;;;;;AAKD,GA7BD;AA+BA;;;;;;;;;AASD,CA/CD;;AAiDA,IAAMO,WAAW;AAAA;AAAA;AAAA;AAAA;AAAA,2BAAG,iBAAOC,KAAP,EAAcC,QAAd,EAAwB3B,SAAxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBACQ0B,KAAK,CAACE,MAAN,CAAaD,QAAQ,CAACzB,OAAtB,CADR;;AAAA;AACZH,YAAAA,WADY;AAElBD,YAAAA,iBAAiB,CAACC,WAAD,EAAcC,SAAd,CAAjB;AACA6B,YAAAA,qBAAqB,CAAC,YAAM;AAC1BJ,cAAAA,WAAW,CAACC,KAAD,EAAQC,QAAR,EAAkB3B,SAAlB,CAAX;AACD,aAFoB,CAArB;;AAHkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAXyB,WAAW;AAAA;AAAA;AAAA,GAAjB;;AAQA,IAAMK,cAAc,GAAG,SAAjBA,cAAiB,CAACJ,KAAD,EAAQC,QAAR,EAAkB3B,SAAlB,EAA6B+B,YAA7B,EAA8C;AACnElC,EAAAA,SAAS,CAAC,YAAM;AACd,QAAI6B,KAAK,IAAIK,YAAb,EAA2B;AACzBN,MAAAA,WAAW,CAACC,KAAD,EAAQC,QAAR,EAAkB3B,SAAlB,CAAX;AACD;AACF,GAJQ,EAIN,CAACA,SAAD,EAAY0B,KAAZ,EAAmBK,YAAnB,EAAiCJ,QAAjC,CAJM,CAAT;AAKD,CAND;;AAQA,eAAeG,cAAf","sourcesContent":["import { useEffect } from 'react'\n\nconst renderPredictions = (predictions, canvasRef) => {\n  const ctx = canvasRef.current.getContext('2d')\n  ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height)\n  // Font options.\n  const font = '16px sans-serif'\n  ctx.font = font\n  ctx.textBaseline = 'top'\n  predictions.forEach(prediction => {\n    const x = prediction.bbox[0]\n    const y = prediction.bbox[1]\n    const width = prediction.bbox[2]\n    const height = prediction.bbox[3]\n    // Draw the bounding box.\n    ctx.strokeStyle = '#00FFFF'\n    ctx.lineWidth = 4\n    ctx.strokeRect(x, y, width, height*2)\n\n    var pixelData = ctx.getImageData(x, y , width, height*2);\n    var avg, i;\n    // apply a  simple greyscale transformation\n    for( i = 0; i < pixelData.data.length; i ++ ) {\n      pixelData.data[ i ] = '#000FFF';\n      pixelData.data[ i + 1 ] = '#000FFF';\n      pixelData.data[ i + 2 ] = '#000FFF';\n    }\n\n    ctx.putImageData(pixelData, 0, 0)\n\n  \n  \n    // Draw the label background.\n    /*ctx.fillStyle = '#00FFFF'\n    const textWidth = ctx.measureText(prediction.class).width\n    const textHeight = parseInt(font, 10) // base 10\n    ctx.fillRect(x, y, textWidth + 4, textHeight + 4)\n    */\n  })\n  \n  /*\n  predictions.forEach(prediction => {\n    const x = prediction.bbox[0]\n    const y = prediction.bbox[1]\n    // Draw the text last to ensure it's on top.\n    ctx.fillStyle = '#000000'\n    ctx.fillText(prediction.class, x, y)\n  })\n  */\n}\n\nconst detectFrame = async (model, videoRef, canvasRef) => {\n  const predictions = await model.detect(videoRef.current)\n  renderPredictions(predictions, canvasRef)\n  requestAnimationFrame(() => {\n    detectFrame(model, videoRef, canvasRef)\n  })\n}\n\nconst useBoxRenderer = (model, videoRef, canvasRef, shouldRender) => {\n  useEffect(() => {\n    if (model && shouldRender) {\n      detectFrame(model, videoRef, canvasRef)\n    }\n  }, [canvasRef, model, shouldRender, videoRef])\n}\n\nexport default useBoxRenderer\n"]},"metadata":{},"sourceType":"module"}