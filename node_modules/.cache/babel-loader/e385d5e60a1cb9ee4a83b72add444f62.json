{"ast":null,"code":"import _regeneratorRuntime from \"/home/tchbek/Desktop/object-detection-react/node_modules/@babel/runtime/regenerator\";\nimport _slicedToArray from \"/home/tchbek/Desktop/object-detection-react/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _asyncToGenerator from \"/home/tchbek/Desktop/object-detection-react/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport * as tf from '@tensorflow/tfjs';\n\nvar calculateMaxScores = function calculateMaxScores(scores, numBoxes, numClasses) {\n  var maxes = [];\n  var classes = [];\n\n  for (var i = 0; i < numBoxes; i++) {\n    var max = Number.MIN_VALUE;\n    var index = -1;\n\n    for (var j = 0; j < numClasses; j++) {\n      if (scores[i * numClasses + j] > max) {\n        max = scores[i * numClasses + j];\n        index = j;\n      }\n    }\n\n    maxes[i] = max;\n    classes[i] = index;\n  }\n\n  return [maxes, classes];\n};\n\nvar buildDetectedObjects = function buildDetectedObjects(width, height, boxes, scores, indexes, classes, labels) {\n  var count = indexes.length;\n  var objects = [];\n\n  for (var i = 0; i < count; i++) {\n    var bbox = [];\n\n    for (var j = 0; j < 4; j++) {\n      bbox[j] = boxes[indexes[i] * 4 + j];\n    }\n\n    var minY = bbox[0] * height;\n    var minX = bbox[1] * width;\n    var maxY = bbox[2] * height;\n    var maxX = bbox[3] * width;\n    bbox[0] = minX;\n    bbox[1] = minY;\n    bbox[2] = maxX - minX;\n    bbox[3] = maxY - minY;\n    objects.push({\n      bbox: bbox,\n      class: labels[parseInt(classes[indexes[i]])],\n      score: scores[indexes[i]]\n    });\n  }\n\n  return objects;\n};\n\nvar runPrediction =\n/*#__PURE__*/\nfunction () {\n  var _ref = _asyncToGenerator(\n  /*#__PURE__*/\n  _regeneratorRuntime.mark(function _callee(graph, labels, input) {\n    var batched, height, width, result, scores, boxes, _calculateMaxScores, _calculateMaxScores2, maxScores, classes, prevBackend, indexTensor, indexes;\n\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            batched = tf.tidy(function () {\n              var img = tf.browser.fromPixels(input); // Reshape to a single-element batch so we can pass it to executeAsync.\n\n              return img.expandDims(0);\n            });\n            height = batched.shape[1];\n            width = batched.shape[2];\n            _context.next = 5;\n            return graph.executeAsync(batched);\n\n          case 5:\n            result = _context.sent;\n            scores = result[0].dataSync();\n            boxes = result[1].dataSync(); // clean the webgl tensors\n\n            batched.dispose();\n            tf.dispose(result);\n            _calculateMaxScores = calculateMaxScores(scores, result[0].shape[1], result[0].shape[2]), _calculateMaxScores2 = _slicedToArray(_calculateMaxScores, 2), maxScores = _calculateMaxScores2[0], classes = _calculateMaxScores2[1];\n            prevBackend = tf.getBackend(); // run post process in cpu\n\n            tf.setBackend('cpu');\n            indexTensor = tf.tidy(function () {\n              var boxes2 = tf.tensor2d(boxes, [result[1].shape[1], result[1].shape[3]]);\n              return tf.image.nonMaxSuppression(boxes2, maxScores, 20, // maxNumBoxes\n              0.5, // iou_threshold\n              0.5 // score_threshold\n              );\n            });\n            indexes = indexTensor.dataSync();\n            indexTensor.dispose(); // restore previous backend\n\n            tf.setBackend(prevBackend);\n            return _context.abrupt(\"return\", buildDetectedObjects(width, height, boxes, maxScores, indexes, classes, labels));\n\n          case 18:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n\n  return function runPrediction(_x, _x2, _x3) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nexport default {\n  load: function () {\n    var _load = _asyncToGenerator(\n    /*#__PURE__*/\n    _regeneratorRuntime.mark(function _callee3(path) {\n      var graphPath, labelsPath, graphPromise, labelsPromise, _ref2, _ref3, graph, labels;\n\n      return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n        while (1) {\n          switch (_context3.prev = _context3.next) {\n            case 0:\n              graphPath = path + '/model.json';\n              labelsPath = path + '/labels.json';\n              graphPromise = tf.loadGraphModel(graphPath);\n              labelsPromise = fetch(labelsPath).then(function (data) {\n                return data.json();\n              });\n              _context3.next = 6;\n              return Promise.all([graphPromise, labelsPromise]);\n\n            case 6:\n              _ref2 = _context3.sent;\n              _ref3 = _slicedToArray(_ref2, 2);\n              graph = _ref3[0];\n              labels = _ref3[1];\n              return _context3.abrupt(\"return\", {\n                detect: function () {\n                  var _detect = _asyncToGenerator(\n                  /*#__PURE__*/\n                  _regeneratorRuntime.mark(function _callee2(input) {\n                    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n                      while (1) {\n                        switch (_context2.prev = _context2.next) {\n                          case 0:\n                            _context2.next = 2;\n                            return runPrediction(graph, labels, input);\n\n                          case 2:\n                            return _context2.abrupt(\"return\", _context2.sent);\n\n                          case 3:\n                          case \"end\":\n                            return _context2.stop();\n                        }\n                      }\n                    }, _callee2);\n                  }));\n\n                  function detect(_x5) {\n                    return _detect.apply(this, arguments);\n                  }\n\n                  return detect;\n                }()\n              });\n\n            case 11:\n            case \"end\":\n              return _context3.stop();\n          }\n        }\n      }, _callee3);\n    }));\n\n    function load(_x4) {\n      return _load.apply(this, arguments);\n    }\n\n    return load;\n  }()\n};","map":null,"metadata":{},"sourceType":"module"}